{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "pd.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FSM Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata: {'users': 1, 'caches': 1, 'number of files': 100, 'cache size': 10, 'time': 1000000, 'dataset': 'syntheticfsm', 'col': -1, 'offset': -1, 'algo': 'iplc', 'hitrate_leadcache': 0.300896, 'hitrate': 0.554833}\n",
      "\n",
      "Only states with at least 200 visits are considered.\n",
      "Sorted in desc orderd of visits. \n",
      "Average hitrate: 0.642\n"
     ]
    }
   ],
   "source": [
    "# file request at each state is generated uniformly at random\n",
    "with pd.HDFStore('data/syntheticfsm/syntheticfsm_col-1_iplc_multifsm_u1_c1_t1000000_d1_f100_04_17_22_04_04.h5') as storage:\n",
    "    df = storage['df']\n",
    "    metadata = storage.get_storer('df').attrs.metadata\n",
    "    # metadata['offset']=3000\n",
    "    # _=metadata.pop('col')\n",
    "    # storage.get_storer('df').attrs.metadata=metadata\n",
    "    _ = metadata.pop('network_graph')\n",
    "\n",
    "    cutoff=200\n",
    "    df1 = df.drop(df[df['visits'] < cutoff].index)\n",
    "    hitrate_filtered=df1['hits'].sum()/df1['visits'].sum()\n",
    "    df1.sort_values(by=['fsm','visits'], inplace=True, ascending=[True,False])\n",
    "\n",
    "    print(f'metadata: {metadata}\\n')\n",
    "    print(f'Only states with at least {cutoff} visits are considered.')\n",
    "    print(f'Sorted in desc orderd of visits. \\nAverage hitrate: {hitrate_filtered:0.3}')\n",
    "    # df1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata: {'users': 1, 'caches': 1, 'number of files': 100, 'cache size': 10, 'time': 1000000, 'dataset': 'syntheticfsm', 'col': -1, 'offset': -1, 'algo': 'markov_offline', 'hitrate_leadcache': 0.300896, 'hitrate': 0.7858657858657858}\n",
      "\n",
      "Only states with at least 200 visits are considered.\n",
      "Sorted in desc orderd of visits. \n",
      "Average hitrate: 0.786\n"
     ]
    }
   ],
   "source": [
    "# file request at each state is generated uniformly at random\n",
    "with pd.HDFStore('data/syntheticfsm/syntheticfsm_col-1_markov_offline_multifsm_u1_c1_t1000000_d1_f100_04_17_21_24_20.h5') as storage:\n",
    "    df = storage['df']\n",
    "    metadata = storage.get_storer('df').attrs.metadata\n",
    "    # metadata['offset']=3000\n",
    "    # _=metadata.pop('col')\n",
    "    # storage.get_storer('df').attrs.metadata=metadata\n",
    "    _ = metadata.pop('network_graph')\n",
    "\n",
    "    cutoff=200\n",
    "    df1 = df.drop(df[df['visits'] < cutoff].index)\n",
    "    hitrate_filtered=df1['hits'].sum()/df1['visits'].sum()\n",
    "    df1.sort_values(by=['fsm','visits'], inplace=True, ascending=[True,False])\n",
    "\n",
    "    print(f'metadata: {metadata}\\n')\n",
    "    print(f'Only states with at least {cutoff} visits are considered.')\n",
    "    print(f'Sorted in desc orderd of visits. \\nAverage hitrate: {hitrate_filtered:0.3}')\n",
    "    # df1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata: {'users': 1, 'caches': 1, 'number of files': 50, 'cache size': 5, 'time': 500000, 'dataset': 'syntheticfsm', 'col': -1, 'offset': -1, 'algo': 'markov_offline', 'hitrate_leadcache': 0.242522, 'hitrate': 0.683763367526735}\n",
      "\n",
      "Only states with at least 200 visits are considered.\n",
      "Sorted in desc orderd of visits. \n",
      "Average hitrate: 0.684\n"
     ]
    }
   ],
   "source": [
    "# file request at each state is generated using the probability vector [0.5,0.25,0.125,0.0625,0.0625] using an FSM with 50 state\n",
    "with pd.HDFStore('data/syntheticfsm/syntheticfsm_col-1_markov_offline_multifsm_u1_c1_t500000_d1_f50_04_18_01_15_54.h5') as storage:\n",
    "    df = storage['df']\n",
    "    metadata = storage.get_storer('df').attrs.metadata\n",
    "    # metadata['offset']=3000\n",
    "    # _=metadata.pop('col')\n",
    "    # storage.get_storer('df').attrs.metadata=metadata\n",
    "    _ = metadata.pop('network_graph')\n",
    "\n",
    "    cutoff=200\n",
    "    df1 = df.drop(df[df['visits'] < cutoff].index)\n",
    "    hitrate_filtered=df1['hits'].sum()/df1['visits'].sum()\n",
    "    df1.sort_values(by=['fsm','visits'], inplace=True, ascending=[True,False])\n",
    "\n",
    "    print(f'metadata: {metadata}\\n')\n",
    "    print(f'Only states with at least {cutoff} visits are considered.')\n",
    "    print(f'Sorted in desc orderd of visits. \\nAverage hitrate: {hitrate_filtered:0.3}')\n",
    "    # df1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata: {'users': 1, 'caches': 1, 'number of files': 50, 'cache size': 5, 'time': 500000, 'dataset': 'syntheticfsm', 'col': -1, 'offset': -1, 'algo': 'iplc', 'hitrate_leadcache': 0.242522, 'hitrate': 0.615958}\n",
      "\n",
      "Only states with at least 200 visits are considered.\n",
      "Sorted in desc orderd of visits. \n",
      "Average hitrate: 0.571\n"
     ]
    }
   ],
   "source": [
    "# file request at each state is generated using the probability vector [0.5,0.25,0.125,0.0625,0.0625] using an FSM with 50 state\n",
    "with pd.HDFStore('data/syntheticfsm/syntheticfsm_col-1_iplc_multifsm_u1_c1_t500000_d1_f50_04_18_01_30_58.h5') as storage:\n",
    "    df = storage['df']\n",
    "    metadata = storage.get_storer('df').attrs.metadata\n",
    "    # metadata['offset']=3000\n",
    "    # _=metadata.pop('col')\n",
    "    # storage.get_storer('df').attrs.metadata=metadata\n",
    "    _ = metadata.pop('network_graph')\n",
    "\n",
    "    cutoff=200\n",
    "    df1 = df.drop(df[df['visits'] < cutoff].index)\n",
    "    hitrate_filtered=df1['hits'].sum()/df1['visits'].sum()\n",
    "    df1.sort_values(by=['fsm','visits'], inplace=True, ascending=[True,False])\n",
    "\n",
    "    print(f'metadata: {metadata}\\n')\n",
    "    print(f'Only states with at least {cutoff} visits are considered.')\n",
    "    print(f'Sorted in desc orderd of visits. \\nAverage hitrate: {hitrate_filtered:0.3}')\n",
    "    # df1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata: {'users': 1, 'caches': 1, 'number of files': 50, 'cache size': 5, 'time': 1000000, 'dataset': 'syntheticfsm', 'col': -1, 'offset': -1, 'algo': 'iplc', 'hitrate_leadcache': 0, 'hitrate': 0.639941, 'markov_order': 2}\n",
      "\n",
      "Only states with at least 200 visits are considered.\n",
      "Sorted in desc orderd of visits. \n",
      "Average hitrate: 0.623\n"
     ]
    }
   ],
   "source": [
    "# file request at each state is generated using the probability vector [0.5,0.25,0.125,0.0625,0.0625] using an FSM with 100 state\n",
    "with pd.HDFStore('data/syntheticfsm/syntheticfsm_col-1_iplc_multifsm_u1_c1_t1000000_d1_f50_k2_04_19_20_25_54.h5') as storage:\n",
    "    df = storage['df']\n",
    "    metadata = storage.get_storer('df').attrs.metadata\n",
    "    # metadata['offset']=3000\n",
    "    # _=metadata.pop('col')\n",
    "    # storage.get_storer('df').attrs.metadata=metadata\n",
    "    _ = metadata.pop('network_graph')\n",
    "\n",
    "    cutoff=200\n",
    "    df1 = df.drop(df[df['visits'] < cutoff].index)\n",
    "    hitrate_filtered=df1['hits'].sum()/df1['visits'].sum()\n",
    "    df1.sort_values(by=['fsm','visits'], inplace=True, ascending=[True,False])\n",
    "\n",
    "    print(f'metadata: {metadata}\\n')\n",
    "    print(f'Only states with at least {cutoff} visits are considered.')\n",
    "    print(f'Sorted in desc orderd of visits. \\nAverage hitrate: {hitrate_filtered:0.3}')\n",
    "    # df1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata: {'users': 1, 'caches': 1, 'number of files': 50, 'cache size': 5, 'time': 500000, 'dataset': 'syntheticfsm', 'col': -1, 'offset': -1, 'algo': 'iplc', 'hitrate_leadcache': 0.178822, 'hitrate': 0.537364}\n",
      "\n",
      "Only states with at least 200 visits are considered.\n",
      "Sorted in desc orderd of visits. \n",
      "Average hitrate: 0.429\n"
     ]
    }
   ],
   "source": [
    "# file request at each state is generated using the probability vector [0.5,0.25,0.125,0.0625,0.0625] using an FSM with 100 state\n",
    "with pd.HDFStore('data/syntheticfsm/syntheticfsm_col-1_iplc_multifsm_u1_c1_t500000_d1_f50_04_19_19_18_01.h5') as storage:\n",
    "    df = storage['df']\n",
    "    metadata = storage.get_storer('df').attrs.metadata\n",
    "    # metadata['offset']=3000\n",
    "    # _=metadata.pop('col')\n",
    "    # storage.get_storer('df').attrs.metadata=metadata\n",
    "    _ = metadata.pop('network_graph')\n",
    "\n",
    "    cutoff=200\n",
    "    df1 = df.drop(df[df['visits'] < cutoff].index)\n",
    "    hitrate_filtered=df1['hits'].sum()/df1['visits'].sum()\n",
    "    df1.sort_values(by=['fsm','visits'], inplace=True, ascending=[True,False])\n",
    "\n",
    "    print(f'metadata: {metadata}\\n')\n",
    "    print(f'Only states with at least {cutoff} visits are considered.')\n",
    "    print(f'Sorted in desc orderd of visits. \\nAverage hitrate: {hitrate_filtered:0.3}')\n",
    "    # df1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata: {'users': 1, 'caches': 1, 'number of files': 50, 'cache size': 5, 'time': 500000, 'dataset': 'syntheticfsm', 'col': -1, 'offset': -1, 'algo': 'markov_online', 'hitrate_leadcache': 0.178822, 'hitrate': 0.5485970971941944}\n",
      "\n",
      "Only states with at least 200 visits are considered.\n",
      "Sorted in desc orderd of visits. \n",
      "Average hitrate: 0.549\n"
     ]
    }
   ],
   "source": [
    "# file request at each state is generated using the probability vector [0.5,0.25,0.125,0.0625,0.0625] using an FSM with 100 state\n",
    "with pd.HDFStore('data/syntheticfsm/syntheticfsm_col-1_markov_online_multifsm_u1_c1_t500000_d1_f50_04_19_19_33_56.h5') as storage:\n",
    "    df = storage['df']\n",
    "    metadata = storage.get_storer('df').attrs.metadata\n",
    "    # metadata['offset']=3000\n",
    "    # _=metadata.pop('col')\n",
    "    # storage.get_storer('df').attrs.metadata=metadata\n",
    "    _ = metadata.pop('network_graph')\n",
    "\n",
    "    cutoff=200\n",
    "    df1 = df.drop(df[df['visits'] < cutoff].index)\n",
    "    hitrate_filtered=df1['hits'].sum()/df1['visits'].sum()\n",
    "    df1.sort_values(by=['fsm','visits'], inplace=True, ascending=[True,False])\n",
    "\n",
    "    print(f'metadata: {metadata}\\n')\n",
    "    print(f'Only states with at least {cutoff} visits are considered.')\n",
    "    print(f'Sorted in desc orderd of visits. \\nAverage hitrate: {hitrate_filtered:0.3}')\n",
    "    # df1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata: {'users': 1, 'caches': 1, 'number of files': 50, 'cache size': 5, 'time': 500000, 'dataset': 'syntheticfsm', 'col': -1, 'offset': -1, 'algo': 'markov_online', 'hitrate_leadcache': 0.178822, 'hitrate': 0.9093896375585502, 'markov_order': 2}\n",
      "\n",
      "Only states with at least 200 visits are considered.\n",
      "Sorted in desc orderd of visits. \n",
      "Average hitrate: 0.914\n"
     ]
    }
   ],
   "source": [
    "# file request at each state is generated using the probability vector [0.5,0.25,0.125,0.0625,0.0625] using an FSM with 100 state\n",
    "with pd.HDFStore('data/syntheticfsm/syntheticfsm_col-1_markov_online_multifsm_u1_c1_t500000_d1_f50_k2_04_19_19_49_56.h5') as storage:\n",
    "    df = storage['df']\n",
    "    metadata = storage.get_storer('df').attrs.metadata\n",
    "    # metadata['offset']=3000\n",
    "    # _=metadata.pop('col')\n",
    "    # storage.get_storer('df').attrs.metadata=metadata\n",
    "    _ = metadata.pop('network_graph')\n",
    "\n",
    "    cutoff=200\n",
    "    df1 = df.drop(df[df['visits'] < cutoff].index)\n",
    "    hitrate_filtered=df1['hits'].sum()/df1['visits'].sum()\n",
    "    df1.sort_values(by=['fsm','visits'], inplace=True, ascending=[True,False])\n",
    "\n",
    "    print(f'metadata: {metadata}\\n')\n",
    "    print(f'Only states with at least {cutoff} visits are considered.')\n",
    "    print(f'Sorted in desc orderd of visits. \\nAverage hitrate: {hitrate_filtered:0.3}')\n",
    "    # df1[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata: {'users': 1, 'caches': 1, 'number of files': 300, 'cache size': 30, 'time': 135711, 'dataset': 'cmu', 'algo': 'iplc', 'hitrate_leadcache': 0.9171400991813486, 'hitrate': 0.8408014088762149, 'offset': 3000}\n",
      "\n",
      "Only states with at least 200 visits are considered.\n",
      "Sorted in desc orderd of visits. \n",
      "Average hitrate: 0.895\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore('data/cmu/cmu_offset3k_iplc_multifsm_u1_c1_t135711_d1_f300_11_11_22_51_20.h5') as storage:\n",
    "    df = storage['df']\n",
    "    metadata = storage.get_storer('df').attrs.metadata\n",
    "    # metadata['offset']=3000\n",
    "    # _=metadata.pop('col')\n",
    "    # storage.get_storer('df').attrs.metadata=metadata\n",
    "    _ = metadata.pop('network_graph')\n",
    "\n",
    "    cutoff=200\n",
    "    df1 = df.drop(df[df['visits'] < cutoff].index)\n",
    "    hitrate_filtered=df1['hits'].sum()/df1['visits'].sum()\n",
    "    df1.sort_values(by=['fsm','visits'], inplace=True, ascending=[True,False])\n",
    "\n",
    "    print(f'metadata: {metadata}\\n')\n",
    "    print(f'Only states with at least {cutoff} visits are considered.')\n",
    "    print(f'Sorted in desc orderd of visits. \\nAverage hitrate: {hitrate_filtered:0.3}')\n",
    "    # df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata: {'users': 1, 'caches': 1, 'number of files': 300, 'cache size': 30, 'time': 123294, 'dataset': 'cmu', 'offset': 7500, 'algo': 'iplc', 'hitrate_leadcache': 0.9072947588690448, 'hitrate': 0.7999983778610475}\n",
      "\n",
      "Only states with at least 200 visits are considered.\n",
      "Sorted in desc orderd of visits. \n",
      "Average hitrate: 0.883\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore('data/cmu/cmu_col-1_iplc_multifsm_u1_c1_t123294_d1_f300_11_12_12_23_35.h5') as storage:\n",
    "    df = storage['df']\n",
    "    metadata = storage.get_storer('df').attrs.metadata\n",
    "    # metadata['offset']=3000\n",
    "    # _=metadata.pop('col')\n",
    "    # storage.get_storer('df').attrs.metadata=metadata\n",
    "    _ = metadata.pop('network_graph')\n",
    "\n",
    "    cutoff=200\n",
    "    df1 = df.drop(df[df['visits'] < cutoff].index)\n",
    "    hitrate_filtered=df1['hits'].sum()/df1['visits'].sum()\n",
    "    df1.sort_values(by=['fsm','visits'], inplace=True, ascending=[True,False])\n",
    "\n",
    "    print(f'metadata: {metadata}\\n')\n",
    "    print(f'Only states with at least {cutoff} visits are considered.')\n",
    "    print(f'Sorted in desc orderd of visits. \\nAverage hitrate: {hitrate_filtered:0.3}')\n",
    "    # df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata: {'users': 10, 'caches': 4, 'number of files': 300, 'cache size': 30, 'time': 2320, 'dataset': 'cmu', 'algo': 'iplc', 'hitrate_leadcache': 0.5651293103448276, 'hitrate': 0.5628017241379311, 'offset': 0}\n",
      "\n",
      "Only states with at least 50 visits are considered.\n",
      "Sorted in desc orderd of visits. \n",
      "Average hitrate: 0.59\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore('data/cmu/cmu_old_iplc_multifsm_u10_c4_t2320_d6_f300_11_10_20_30_07.h5') as storage:\n",
    "    df = storage['df']\n",
    "    metadata = storage.get_storer('df').attrs.metadata\n",
    "    # metadata['offset']=0\n",
    "    # _=metadata.pop('col')\n",
    "    # storage.get_storer('df').attrs.metadata=metadata\n",
    "    _ = metadata.pop('network_graph')\n",
    "\n",
    "    cutoff=50\n",
    "    df1 = df.drop(df[df['visits'] < cutoff].index)\n",
    "    hitrate_filtered=df1['hits'].sum()/df1['visits'].sum()\n",
    "    df1.sort_values(by=['fsm','visits'], inplace=True, ascending=[True,False])\n",
    "\n",
    "    print(f'metadata: {metadata}\\n')\n",
    "    print(f'Only states with at least {cutoff} visits are considered.')\n",
    "    print(f'Sorted in desc orderd of visits. \\nAverage hitrate: {hitrate_filtered:0.3}')\n",
    "    # df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata: {'users': 10, 'caches': 4, 'number of files': 300, 'cache size': 30, 'time': 10000, 'dataset': 'cmu', 'offset': 7500, 'algo': 'iplc', 'hitrate_leadcache': 0.73282, 'hitrate': 0.76799}\n",
      "\n",
      "Only states with at least 200 visits are considered.\n",
      "Sorted in desc orderd of visits. \n",
      "Average hitrate: 0.77\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore('data/cmu/cmu_col-1_iplc_multifsm_u10_c4_t10000_d6_f300_11_12_15_47_20.h5') as storage:\n",
    "    df = storage['df']\n",
    "    metadata = storage.get_storer('df').attrs.metadata\n",
    "    # metadata['offset']=3000\n",
    "    # _=metadata.pop('col')\n",
    "    # storage.get_storer('df').attrs.metadata=metadata\n",
    "    _ = metadata.pop('network_graph')\n",
    "\n",
    "    cutoff=200\n",
    "    df1 = df.drop(df[df['visits'] < cutoff].index)\n",
    "    hitrate_filtered=df1['hits'].sum()/df1['visits'].sum()\n",
    "    df1.sort_values(by=['fsm','visits'], inplace=True, ascending=[True,False])\n",
    "\n",
    "    print(f'metadata: {metadata}\\n')\n",
    "    print(f'Only states with at least {cutoff} visits are considered.')\n",
    "    print(f'Sorted in desc orderd of visits. \\nAverage hitrate: {hitrate_filtered:0.3}')\n",
    "    # df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata: {'users': 15, 'caches': 7, 'number of files': 300, 'cache size': 30, 'time': 1546, 'dataset': 'cmu', 'algo': 'iplc', 'hitrate_leadcache': 0.6432082794307892, 'hitrate': 0.5989650711513583, 'offset': 0}\n",
      "\n",
      "Only states with at least 50 visits are considered.\n",
      "Sorted in desc orderd of visits. \n",
      "Average hitrate: 0.619\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore('data/cmu/cmu_old_iplc_multifsm_u15_c7_t1546_d8_f300_11_10_21_09_33.h5') as storage:\n",
    "    df = storage['df']\n",
    "    metadata = storage.get_storer('df').attrs.metadata\n",
    "    # metadata['offset']=0\n",
    "    # metadata['hitrate_leadcache']=0.6432082794307892\n",
    "    # _=metadata.pop('col')\n",
    "    # storage.get_storer('df').attrs.metadata=metadata\n",
    "    _ = metadata.pop('network_graph')\n",
    "\n",
    "    cutoff=50\n",
    "    df1 = df.drop(df[df['visits'] < cutoff].index)\n",
    "    hitrate_filtered=df1['hits'].sum()/df1['visits'].sum()\n",
    "    df1.sort_values(by=['fsm','visits'], inplace=True, ascending=[True,False])\n",
    "\n",
    "    print(f'metadata: {metadata}\\n')\n",
    "    print(f'Only states with at least {cutoff} visits are considered.')\n",
    "    print(f'Sorted in desc orderd of visits. \\nAverage hitrate: {hitrate_filtered:0.3}')\n",
    "    # df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata: {'users': 15, 'caches': 7, 'number of files': 300, 'cache size': 30, 'time': 5000, 'dataset': 'cmu', 'offset': 3000, 'algo': 'iplc', 'hitrate_leadcache': 0.77488, 'hitrate': 0.7681066666666667}\n",
      "\n",
      "Only states with at least 200 visits are considered.\n",
      "Sorted in desc orderd of visits. \n",
      "Average hitrate: 0.775\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore('data/cmu/cmu_col-1_iplc_multifsm_u15_c7_t5000_d8_f300_11_12_11_32_12.h5') as storage:\n",
    "    df = storage['df']\n",
    "    metadata = storage.get_storer('df').attrs.metadata\n",
    "    # metadata['offset']=0\n",
    "    # metadata['hitrate_leadcache']=0.77488\n",
    "    # _=metadata.pop('col')\n",
    "    # storage.get_storer('df').attrs.metadata=metadata\n",
    "    _ = metadata.pop('network_graph')\n",
    "\n",
    "    cutoff=200\n",
    "    df1 = df.drop(df[df['visits'] < cutoff].index)\n",
    "    hitrate_filtered=df1['hits'].sum()/df1['visits'].sum()\n",
    "    df1.sort_values(by=['fsm','visits'], inplace=True, ascending=[True,False])\n",
    "\n",
    "    print(f'metadata: {metadata}\\n')\n",
    "    print(f'Only states with at least {cutoff} visits are considered.')\n",
    "    print(f'Sorted in desc orderd of visits. \\nAverage hitrate: {hitrate_filtered:0.3}')\n",
    "    # df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeated requests 1 to 50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata: {'users': 1, 'caches': 1, 'number of files': 50, 'cache size': 5, 'time': 50000, 'dataset': 'synthetic', 'col': 3, 'algo': 'iplc_multiple_fsm', 'hitrate_leadcache': 0.09896, 'hitrate_iplc': 0.9195}\n",
      "\n",
      "Only states with at least 200 visits are considered.\n",
      "Sorted in desc orderd of visits. \n",
      "Average hitrate: 0.0796\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore('data/synthetic/synthetic_col3_iplc_multifsm_u1_c1_t50000_d1_f50_11_03_11_11_47.h5') as storage:\n",
    "    df = storage['df']\n",
    "    metadata = storage.get_storer('df').attrs.metadata\n",
    "    _ = metadata.pop('network_graph')\n",
    "\n",
    "    cutoff=200\n",
    "    df1 = df.drop(df[df['visits'] < cutoff].index)\n",
    "    hitrate_filtered=df1['hits'].sum()/df1['visits'].sum()\n",
    "    df1.sort_values(by=['fsm','visits'], inplace=True, ascending=[True,False])\n",
    "\n",
    "    print(f'metadata: {metadata}\\n')\n",
    "    print(f'Only states with at least {cutoff} visits are considered.')\n",
    "    print(f'Sorted in desc orderd of visits. \\nAverage hitrate: {hitrate_filtered:0.3}')\n",
    "    # df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ratings 1M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \n",
    "<font size=\"3\">\n",
    "\n",
    "| dataset | users | cache |\n",
    "| ------- | ----- | ----- |\n",
    "| 0       | 1     | 1     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata: {'users': 1, 'caches': 1, 'number of files': 300, 'cache size': 30, 'time': 82070, 'dataset': 'ratings', 'algo': 'iplc_multiple_fsm', 'hitrate_leadcache': 0.4429998781527964, 'hitrate_iplc': 0.3946143536005849}\n",
      "\n",
      "Only states with at least 200 visits are considered.\n",
      "Sorted in desc orderd of visits. \n",
      "Average hitrate: 0.479\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore('data/ratings/ratings_col0_iplc_multifsm_u1_c1_t82070_d1_f300_10_31_19_35_42.h5') as storage:\n",
    "    df = storage['df']\n",
    "    metadata = storage.get_storer('df').attrs.metadata\n",
    "    _ = metadata.pop('network_graph')\n",
    "\n",
    "    cutoff=200\n",
    "    df1 = df.drop(df[df['visits'] < cutoff].index)\n",
    "    hitrate_filtered=df1['hits'].sum()/df1['visits'].sum()\n",
    "    df1.sort_values(by=['fsm','visits'], inplace=True, ascending=[True,False])\n",
    "\n",
    "    print(f'metadata: {metadata}\\n')\n",
    "    print(f'Only states with at least {cutoff} visits are considered.')\n",
    "    print(f'Sorted in desc orderd of visits. \\nAverage hitrate: {hitrate_filtered:0.3}')\n",
    "    # df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata: {'users': 1, 'caches': 1, 'number of files': 300, 'cache size': 30, 'time': 82070, 'dataset': 'ratings', 'col': 0, 'algo': 'markov_online', 'hitrate_leadcache': 0, 'hitrate': 0.5629043853342919}\n",
      "\n",
      "Only states with at least 50 visits are considered.\n",
      "Sorted in desc orderd of visits. \n",
      "Average hitrate: 0.571\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore('data/ratings/ratings_col0_markov_online_multifsm_u1_c1_t82070_d1_f300_11_04_23_08_19.h5') as storage:\n",
    "    df = storage['df']\n",
    "    metadata = storage.get_storer('df').attrs.metadata\n",
    "    # metadata['algo']='markov_online'\n",
    "    # storage.get_storer('df').attrs.metadata=metadata\n",
    "    _ = metadata.pop('network_graph')\n",
    "\n",
    "    cutoff=50\n",
    "    df1 = df.drop(df[df['visits'] < cutoff].index)\n",
    "    hitrate_filtered=df1['hits'].sum()/df1['visits'].sum()\n",
    "    df1.sort_values(by=['fsm','visits'], inplace=True, ascending=[True,False])\n",
    "\n",
    "    print(f'metadata: {metadata}\\n')\n",
    "    print(f'Only states with at least {cutoff} visits are considered.')\n",
    "    print(f'Sorted in desc orderd of visits. \\nAverage hitrate: {hitrate_filtered:0.3}')\n",
    "    # df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata: {'users': 1, 'caches': 1, 'number of files': 300, 'cache size': 30, 'time': 82070, 'dataset': 'ratings', 'col': 0, 'algo': 'markov_offline', 'hitrate_leadcache': 0, 'hitrate_iplc': 0.7003911438215117}\n",
      "\n",
      "Only states with at least 200 visits are considered.\n",
      "Sorted in desc orderd of visits. \n",
      "Average hitrate: 0.695\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore('data/ratings/ratings_col0_markovoffline_multifsm_u1_c1_t82070_d1_f300_11_02_15_30_33.h5') as storage:\n",
    "    df = storage['df']\n",
    "    metadata = storage.get_storer('df').attrs.metadata\n",
    "    _ = metadata.pop('network_graph')\n",
    "\n",
    "    cutoff=200\n",
    "    df1 = df.drop(df[df['visits'] < cutoff].index)\n",
    "    hitrate_filtered=df1['hits'].sum()/df1['visits'].sum()\n",
    "    df1.sort_values(by=['fsm','visits'], inplace=True, ascending=[True,False])\n",
    "\n",
    "    print(f'metadata: {metadata}\\n')\n",
    "    print(f'Only states with at least {cutoff} visits are considered.')\n",
    "    print(f'Sorted in desc orderd of visits. \\nAverage hitrate: {hitrate_filtered:0.3}')\n",
    "    # df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "<font size=\"3\">\n",
    "\n",
    "| dataset | users | cache |\n",
    "| ------- | ----- | ----- |\n",
    "| 1       | 1     | 1     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata: {'users': 1, 'caches': 1, 'number of files': 300, 'cache size': 30, 'time': 50000, 'dataset': 'ratings', 'col': 1, 'algo': 'iplc_multiple_fsm', 'hitrate_leadcache': 0.47458, 'hitrate_iplc': 0.3819}\n",
      "\n",
      "Only states with at least 200 visits are considered.\n",
      "Sorted in desc orderd of visits. \n",
      "Average hitrate: 0.477\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore('data/ratings/ratings_col1_iplc_multifsm_u1_c1_t50000_d1_f300_10_31_20_03_40.h5') as storage:\n",
    "    df = storage['df']\n",
    "    metadata = storage.get_storer('df').attrs.metadata\n",
    "    _ = metadata.pop('network_graph')\n",
    "\n",
    "    cutoff=200\n",
    "    df1 = df.drop(df[df['visits'] < cutoff].index)\n",
    "    hitrate_filtered=df1['hits'].sum()/df1['visits'].sum()\n",
    "    df1.sort_values(by=['fsm','visits'], inplace=True, ascending=[True,False])\n",
    "\n",
    "    print(f'metadata: {metadata}\\n')\n",
    "    print(f'Only states with at least {cutoff} visits are considered.')\n",
    "    print(f'Sorted in desc orderd of visits. \\nAverage hitrate: {hitrate_filtered:0.3}')\n",
    "    # df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata: {'users': 1, 'caches': 1, 'number of files': 300, 'cache size': 30, 'time': 50000, 'dataset': 'ratings', 'col': 1, 'algo': 'markov_online', 'hitrate_leadcache': 0, 'hitrate_iplc': 0.5479309586191724}\n",
      "\n",
      "Only states with at least 200 visits are considered.\n",
      "Sorted in desc orderd of visits. \n",
      "Average hitrate: 0.619\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore('data/ratings/ratings_col1_markov_online_multifsm_u1_c1_t50000_d1_f300_11_03_02_29_43.h5') as storage:\n",
    "    df = storage['df']\n",
    "    metadata = storage.get_storer('df').attrs.metadata\n",
    "    # metadata['algo']='markov_online'\n",
    "    # storage.get_storer('df').attrs.metadata=metadata\n",
    "    _ = metadata.pop('network_graph')\n",
    "\n",
    "    cutoff=200\n",
    "    df1 = df.drop(df[df['visits'] < cutoff].index)\n",
    "    hitrate_filtered=df1['hits'].sum()/df1['visits'].sum()\n",
    "    df1.sort_values(by=['fsm','visits'], inplace=True, ascending=[True,False])\n",
    "\n",
    "    print(f'metadata: {metadata}\\n')\n",
    "    print(f'Only states with at least {cutoff} visits are considered.')\n",
    "    print(f'Sorted in desc orderd of visits. \\nAverage hitrate: {hitrate_filtered:0.3}')\n",
    "    # df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata: {'users': 1, 'caches': 1, 'number of files': 300, 'cache size': 30, 'time': 50000, 'dataset': 'ratings', 'col': 1, 'algo': 'markov_offline', 'hitrate_leadcache': 0, 'hitrate': 0.7354747094941899}\n",
      "\n",
      "Only states with at least 200 visits are considered.\n",
      "Sorted in desc orderd of visits. \n",
      "Average hitrate: 0.724\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore('data/ratings/ratings_col1_markov_offline_multifsm_u1_c1_t50000_d1_f300_11_04_23_24_00.h5') as storage:\n",
    "    df = storage['df']\n",
    "    metadata = storage.get_storer('df').attrs.metadata\n",
    "    # metadata['algo']='markov_online'\n",
    "    # storage.get_storer('df').attrs.metadata=metadata\n",
    "    _ = metadata.pop('network_graph')\n",
    "\n",
    "    cutoff=200\n",
    "    df1 = df.drop(df[df['visits'] < cutoff].index)\n",
    "    hitrate_filtered=df1['hits'].sum()/df1['visits'].sum()\n",
    "    df1.sort_values(by=['fsm','visits'], inplace=True, ascending=[True,False])\n",
    "\n",
    "    print(f'metadata: {metadata}\\n')\n",
    "    print(f'Only states with at least {cutoff} visits are considered.')\n",
    "    print(f'Sorted in desc orderd of visits. \\nAverage hitrate: {hitrate_filtered:0.3}')\n",
    "    # df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "<font size=\"3\">\n",
    "\n",
    "| dataset | users | cache |\n",
    "| ------- | ----- | ----- |\n",
    "| 2       | 1     | 1     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata: {'users': 1, 'caches': 1, 'number of files': 300, 'cache size': 30, 'time': 50000, 'dataset': 'ratings', 'col': 2, 'algo': 'iplc_multiple_fsm', 'hitrate_leadcache': 0.49248, 'hitrate_iplc': 0.3894}\n",
      "\n",
      "Only states with at least 200 visits are considered.\n",
      "Sorted in desc orderd of visits. \n",
      "Average hitrate: 0.502\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore('data/ratings/ratings_col2_iplc_multifsm_u1_c1_t50000_d1_f300_10_31_20_28_04.h5') as storage:\n",
    "    df = storage['df']\n",
    "    metadata = storage.get_storer('df').attrs.metadata\n",
    "    _ = metadata.pop('network_graph')\n",
    "\n",
    "    cutoff=200\n",
    "    df1 = df.drop(df[df['visits'] < cutoff].index)\n",
    "    hitrate_filtered=df1['hits'].sum()/df1['visits'].sum()\n",
    "    df1.sort_values(by=['fsm','visits'], inplace=True, ascending=[True,False])\n",
    "\n",
    "    print(f'metadata: {metadata}\\n')\n",
    "    print(f'Only states with at least {cutoff} visits are considered.')\n",
    "    print(f'Sorted in desc orderd of visits. \\nAverage hitrate: {hitrate_filtered:0.3}')\n",
    "    # df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata: {'users': 1, 'caches': 1, 'number of files': 300, 'cache size': 30, 'time': 50000, 'dataset': 'ratings', 'col': 2, 'algo': 'markov_online', 'hitrate_leadcache': 0, 'hitrate': 0.5787715754315086}\n",
      "\n",
      "Only states with at least 200 visits are considered.\n",
      "Sorted in desc orderd of visits. \n",
      "Average hitrate: 0.628\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore('data/ratings/ratings_col2_markov_online_multifsm_u1_c1_t50000_d1_f300_11_04_23_48_58.h5') as storage:\n",
    "    df = storage['df']\n",
    "    metadata = storage.get_storer('df').attrs.metadata\n",
    "    _ = metadata.pop('network_graph')\n",
    "\n",
    "    cutoff=200\n",
    "    df1 = df.drop(df[df['visits'] < cutoff].index)\n",
    "    hitrate_filtered=df1['hits'].sum()/df1['visits'].sum()\n",
    "    df1.sort_values(by=['fsm','visits'], inplace=True, ascending=[True,False])\n",
    "\n",
    "    print(f'metadata: {metadata}\\n')\n",
    "    print(f'Only states with at least {cutoff} visits are considered.')\n",
    "    print(f'Sorted in desc orderd of visits. \\nAverage hitrate: {hitrate_filtered:0.3}')\n",
    "    # df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata: {'users': 1, 'caches': 1, 'number of files': 300, 'cache size': 30, 'time': 50000, 'dataset': 'ratings', 'col': 2, 'algo': 'markov_offline', 'hitrate_leadcache': 0, 'hitrate': 0.7434548690973819}\n",
      "\n",
      "Only states with at least 200 visits are considered.\n",
      "Sorted in desc orderd of visits. \n",
      "Average hitrate: 0.73\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore('data/ratings/ratings_col2_markov_offline_multifsm_u1_c1_t50000_d1_f300_11_05_00_05_11.h5') as storage:\n",
    "    df = storage['df']\n",
    "    metadata = storage.get_storer('df').attrs.metadata\n",
    "    _ = metadata.pop('network_graph')\n",
    "\n",
    "    cutoff=200\n",
    "    df1 = df.drop(df[df['visits'] < cutoff].index)\n",
    "    hitrate_filtered=df1['hits'].sum()/df1['visits'].sum()\n",
    "    df1.sort_values(by=['fsm','visits'], inplace=True, ascending=[True,False])\n",
    "\n",
    "    print(f'metadata: {metadata}\\n')\n",
    "    print(f'Only states with at least {cutoff} visits are considered.')\n",
    "    print(f'Sorted in desc orderd of visits. \\nAverage hitrate: {hitrate_filtered:0.3}')\n",
    "    # df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "<font size=\"3\">\n",
    "\n",
    "| dataset | users | cache |\n",
    "| ------- | ----- | ----- |\n",
    "| 3       | 10    | 4     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata: {'users': 10, 'caches': 4, 'number of files': 300, 'cache size': 30, 'time': 5000, 'dataset': 'ratings', 'col': 3, 'algo': 'iplc_multiple_fsm', 'hitrate_leadcache': 0.47992, 'hitrate_iplc': 0.4806}\n",
      "\n",
      "Only states with at least 50 visits are considered.\n",
      "Sorted in desc orderd of visits. \n",
      "Average hitrate: 0.508\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore('data/ratings/ratings_col3_iplc_multifsm_u10_c4_t5000_d6_f300_11_01_14_51_15.h5') as storage:\n",
    "    df = storage['df']\n",
    "    metadata = storage.get_storer('df').attrs.metadata\n",
    "    _ = metadata.pop('network_graph')\n",
    "\n",
    "    cutoff=50\n",
    "    df1 = df.drop(df[df['visits'] < cutoff].index)\n",
    "    hitrate_filtered=df1['hits'].sum()/df1['visits'].sum()\n",
    "    df1.sort_values(by=['fsm','visits'], inplace=True, ascending=[True,False])\n",
    "\n",
    "    print(f'metadata: {metadata}\\n')\n",
    "    print(f'Only states with at least {cutoff} visits are considered.')\n",
    "    print(f'Sorted in desc orderd of visits. \\nAverage hitrate: {hitrate_filtered:0.3}')\n",
    "    # df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata: {'users': 10, 'caches': 4, 'number of files': 300, 'cache size': 30, 'time': 5000, 'dataset': 'ratings', 'col': 3, 'algo': 'markov_online', 'hitrate_leadcache': 0, 'hitrate_iplc': 0.4859771954390878}\n",
      "\n",
      "Only states with at least 50 visits are considered.\n",
      "Sorted in desc orderd of visits. \n",
      "Average hitrate: 0.593\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore('data/ratings/ratings_col3_markov_online_multifsm_u10_c4_t5000_d6_f300_11_03_10_43_55.h5') as storage:\n",
    "    df = storage['df']\n",
    "    metadata = storage.get_storer('df').attrs.metadata\n",
    "    # metadata['algo']='markov_online'\n",
    "    # storage.get_storer('df').attrs.metadata=metadata\n",
    "    _ = metadata.pop('network_graph')\n",
    "\n",
    "    cutoff=50\n",
    "    df1 = df.drop(df[df['visits'] < cutoff].index)\n",
    "    hitrate_filtered=df1['hits'].sum()/df1['visits'].sum()\n",
    "    df1.sort_values(by=['fsm','visits'], inplace=True, ascending=[True,False])\n",
    "\n",
    "    print(f'metadata: {metadata}\\n')\n",
    "    print(f'Only states with at least {cutoff} visits are considered.')\n",
    "    print(f'Sorted in desc orderd of visits. \\nAverage hitrate: {hitrate_filtered:0.3}')\n",
    "    # df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata: {'users': 10, 'caches': 4, 'number of files': 300, 'cache size': 30, 'time': 5000, 'dataset': 'ratings', 'col': 3, 'algo': 'markov_offline', 'hitrate_leadcache': 0, 'hitrate_iplc': 0.865513102620524}\n",
      "\n",
      "Only states with at least 50 visits are considered.\n",
      "Sorted in desc orderd of visits. \n",
      "Average hitrate: 0.875\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore('data/ratings/ratings_col3_markovoffline_multifsm_u10_c4_t5000_d6_f300_11_02_19_32_56.h5') as storage:\n",
    "    df = storage['df']\n",
    "    metadata = storage.get_storer('df').attrs.metadata\n",
    "    # metadata['algo']='markov_offline'\n",
    "    # storage.get_storer('df').attrs.metadata=metadata\n",
    "    _ = metadata.pop('network_graph')\n",
    "\n",
    "    cutoff=50\n",
    "    df1 = df.drop(df[df['visits'] < cutoff].index)\n",
    "    hitrate_filtered=df1['hits'].sum()/df1['visits'].sum()\n",
    "    df1.sort_values(by=['fsm','visits'], inplace=True, ascending=[True,False])\n",
    "\n",
    "    print(f'metadata: {metadata}\\n')\n",
    "    print(f'Only states with at least {cutoff} visits are considered.')\n",
    "    print(f'Sorted in desc orderd of visits. \\nAverage hitrate: {hitrate_filtered:0.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "<font size=\"3\">\n",
    "\n",
    "| dataset | users | cache |\n",
    "| ------- | ----- | ----- |\n",
    "| 4       | 15    | 7     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata: {'users': 15, 'caches': 7, 'number of files': 300, 'cache size': 30, 'time': 5000, 'dataset': 'ratings', 'col': 4, 'algo': 'iplc_multiple_fsm', 'hitrate_leadcache': 0.60236, 'hitrate_iplc': 0.5931733333333333}\n",
      "\n",
      "Only states with at least 50 visits are considered.\n",
      "Sorted in desc orderd of visits. \n",
      "Average hitrate: 0.616\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore('data/ratings/ratings_col4_iplc_multifsm_u15_c7_t5000_d8_f300_11_01_17_44_49.h5') as storage:\n",
    "    df = storage['df']\n",
    "    metadata = storage.get_storer('df').attrs.metadata\n",
    "    _ = metadata.pop('network_graph')\n",
    "\n",
    "    cutoff=50\n",
    "    df1 = df.drop(df[df['visits'] < cutoff].index)\n",
    "    hitrate_filtered=df1['hits'].sum()/df1['visits'].sum()\n",
    "    df1.sort_values(by=['fsm','visits'], inplace=True, ascending=[True,False])\n",
    "\n",
    "    print(f'metadata: {metadata}\\n')\n",
    "    print(f'Only states with at least {cutoff} visits are considered.')\n",
    "    print(f'Sorted in desc orderd of visits. \\nAverage hitrate: {hitrate_filtered:0.3}')\n",
    "    # df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata: {'users': 15, 'caches': 7, 'number of files': 300, 'cache size': 30, 'time': 5000, 'dataset': 'ratings', 'col': 4, 'algo': 'markov_online', 'hitrate_leadcache': 0, 'hitrate_iplc': 0.6400746816029873}\n",
      "\n",
      "Only states with at least 50 visits are considered.\n",
      "Sorted in desc orderd of visits. \n",
      "Average hitrate: 0.72\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore('data/ratings/ratings_col4_markov_online_multifsm_u15_c7_t5000_d8_f300_11_03_04_02_09.h5') as storage:\n",
    "    df = storage['df']\n",
    "    metadata = storage.get_storer('df').attrs.metadata\n",
    "    # metadata['algo']='markov_online'\n",
    "    # storage.get_storer('df').attrs.metadata=metadata\n",
    "    _ = metadata.pop('network_graph')\n",
    "\n",
    "    cutoff=50\n",
    "    df1 = df.drop(df[df['visits'] < cutoff].index)\n",
    "    hitrate_filtered=df1['hits'].sum()/df1['visits'].sum()\n",
    "    df1.sort_values(by=['fsm','visits'], inplace=True, ascending=[True,False])\n",
    "\n",
    "    print(f'metadata: {metadata}\\n')\n",
    "    print(f'Only states with at least {cutoff} visits are considered.')\n",
    "    print(f'Sorted in desc orderd of visits. \\nAverage hitrate: {hitrate_filtered:0.3}')\n",
    "    # df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata: {'users': 10, 'caches': 4, 'number of files': 300, 'cache size': 30, 'time': 5000, 'dataset': 'ratings', 'col': 4, 'algo': 'markov_offline', 'hitrate_leadcache': 0, 'hitrate': 0.8766153230646129}\n",
      "\n",
      "Only states with at least 50 visits are considered.\n",
      "Sorted in desc orderd of visits. \n",
      "Average hitrate: 0.889\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore('data/ratings/ratings_col4_markov_offline_multifsm_u10_c4_t5000_d6_f300_11_05_00_36_06.h5') as storage:\n",
    "    df = storage['df']\n",
    "    metadata = storage.get_storer('df').attrs.metadata\n",
    "    # metadata['algo']='markov_online'\n",
    "    # storage.get_storer('df').attrs.metadata=metadata\n",
    "    _ = metadata.pop('network_graph')\n",
    "\n",
    "    cutoff=50\n",
    "    df1 = df.drop(df[df['visits'] < cutoff].index)\n",
    "    hitrate_filtered=df1['hits'].sum()/df1['visits'].sum()\n",
    "    df1.sort_values(by=['fsm','visits'], inplace=True, ascending=[True,False])\n",
    "\n",
    "    print(f'metadata: {metadata}\\n')\n",
    "    print(f'Only states with at least {cutoff} visits are considered.')\n",
    "    print(f'Sorted in desc orderd of visits. \\nAverage hitrate: {hitrate_filtered:0.3}')\n",
    "    # df1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ccea24c44f962f1a297b9d5136c4a88ea9f80cd6183cc180206da41d7855a428"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
